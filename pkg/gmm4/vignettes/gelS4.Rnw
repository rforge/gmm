\documentclass[11pt,letterpaper]{article}
\usepackage{amsthm}

\usepackage[hmargin=2cm,vmargin=2.5cm]{geometry}
\newtheorem{theorem}{Theorem}
\newtheorem{col}{Corollary}
\newtheorem{lem}{Lemma}
\usepackage[utf8x]{inputenc}
\newtheorem{ass}{Assumption}
\usepackage{amsmath}
\usepackage{verbatim}
\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
  colorlinks,
  citecolor=black,
  filecolor=black,
  linkcolor=black,
  urlcolor=black
}

\bibliographystyle{plainnat}


\author{Pierre Chauss\'e}
\title{\textbf{Generalized Empirical Likelihood with R}}
\begin{document}

\maketitle

\newcommand{\E}{\mathrm{E}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\Prob}{\mathrm{Pr}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Vect}{\mathrm{Vec}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\conP}{\overset{p}{\to}}
\newcommand{\conD}{\overset{d}{\to}}
\newcommand\R{ \mathbb{R} }
\newcommand\N{ \mathbb{N} }
\newcommand\C{ \mathbb{C} }
\newcommand\rv{{\cal R}}
\newcommand\Q{\mathbb{Q}}
\newcommand\PR{{\cal R}}
\newcommand\T{{\cal T}}
\newcommand\Hi{{\cal H}}
\newcommand\La{{\cal L}}
\newcommand\plim{plim}
\renewcommand{\epsilon}{\varepsilon}

\abstract{This an extention of the gmmS4 vignette, to explain how to
  use the package for generalized empirical likelihood estimation.}
%\VignetteIndexEntry{Generalized Empirical Likelihood with R}
%\VignetteDepends{gmm4}
%\VignetteKeywords{empirical likelihood, exponential tilting,
%euclidean empirical likelihood}
%\VignettePackage{gmm4}
%\VignetteEngine{knitr::knitr}
<<echo=FALSE>>=
library(knitr)
opts_chunk$set(size='footnotesize')
@ 

\newpage
\tableofcontents
\newpage

\section{A very brief review of the GEL method}
We present how to use the package to estimate models by the
Generalized Empirical Likelihood method (GEL) (see
\cite{newey-smith04} for the iid case and \cite{anatolyev05} for
weakly dependent processes). We assume that the reader has read the
gmmS4 vignette in which many classes and methods needed are
defined. We first describe the method without going into too much
details. The author can refer to the above papers for a detailed
description, or \cite{chausse10} who explains GEL estimation using the
gmm (\cite{gmm})package. 

The estimation is based on the following moment conditions 
\[
\E[g_i(\theta)]=0,   
\]
For the iid case, the estimator is defined as the solution to either

\[
 \hat{\theta} = \arg\min_{\theta,p_i} \sum_{i=1}^n h_n(p_i) 
\]
subject to,
\[
\sum_{i=1}^n p_ig_i(\theta) = 0 
\]
and
\[
\sum_{i=1}^n p_i=1,
\]
where $h_n(p_i)$ belongs to the following Cressie-Read family of discrepancies:
\[
 h_n(p_i) = \frac{[\gamma(\gamma+1)]^{-1}[(np_i)^{\gamma+1}-1]}{n}, 
\]
or
\begin{equation}\label{gel_obj}
 \hat{\theta} = \arg\min_{\theta}\left[\max_{\lambda} \frac{1}{n}\sum_{i=1}^n\rho\left(\lambda'g_i(\theta)\right)\right]
\end{equation}

The first is the primal and the second is the dual problem, the latter
being preferred in general to define GEL estimators. The vector
$\lambda$ is the Lagrange multiplier associated with the first
constraint in the primal problem. Its estimator plays an important
role in testing the validity of the moment conditions. $\rho(v)$ is a
strictly concave function normalized so that
$\rho'(0)=\rho''(0)=-1$. It can be shown that $\rho(v)=\ln{(1-v)}$
corresponds to Empirical Likelihood (EL) of \cite{owen01} ,
$\rho(v)=-\exp{(v)}$ to the Exponential Tilting (ET) of
\cite{kitamura-stutzer97}, and $\rho(v)=(-v-v^2/2)$ to the Continuous
Updated GMM estimator (CUE) of \cite{hansen-heaton-yaron96}. In the
context of GEL, the CUE is also known at the Euclidean Empirical
Likelihood (EEL), because it corresponds to $h_n(p_i)$ being the
Euclidean distance. 

Once the solution is obtained for $\theta$ and $\lambda$, the implied
probabilities can be computed as follows

\begin{equation}\label{imp_prob}
\hat{p}_i = \frac{\rho'(\hat{\lambda}'g_i(\hat{\theta}))}{\sum_{j=1}^n
  \rho'(\hat{\lambda}'g_j(\hat{\theta}))}
\end{equation}

If we relax the iid assumption, the problem is identical, but the
moment function must be smoothed using a kernel method. \cite{smith01}
proposes to replace $g_i(\theta)$ by:
\[
g^w_i(\theta) = \sum_{s=-m}^m w(s)g_{i-s}(\theta)
\]
where $w(s)$ are kernel based weights that sum to one (see also
\cite{kitamura-stutzer97} and \cite{smith01}. 

\section{An S4 class object for GEL models} \label{sec:gelmodels}

All classes for GEL models inherit directly from ``gmmModels''
classes. It is just a gmmModel class with two additional slots:
``gelType'' and ``wSpec''. The first is a list with the name of the
GEL method and a function for $\rho(v)$, if not already available in
the package. The second slot is used to store information about the
smoothing of $g_i(\theta)$ in the case of non-iid observations. As for
gmmModels, ``gelModels'' is a union class for ``linearGel'',
``nonlinearGel'', ``formulaGel'' and ``functionGel''. They inherit
directly from the associated GMM model class. For example,
``linearGel'' is a class that contains a ``linearGmm'' class object
and the two additional slots. The constructor is the gelModel()
function. We use the same models presented in the gmmS4
vignette:

<<>>=
library(gmm4)
data(simData)
@ 

\begin{itemize}
  \item Linear models:

<<>>=
lin <- gelModel(y~x1+x2, ~x2+z1+z2, data=simData, vcov="iid", gelType="EL")  
lin
@ 

\item Formula-type models:

<<>>=
theta0=c(mu=1,sig=1)
x <- simData$x1
dat <- data.frame(x=x, x2=x^2, x3=x^3, x4=x^4)
gform <- list(x~mu,
              x2~mu^2+sig, 
              x3~mu^3+3*mu*sig,
              x4~mu^4+6*mu^2*sig+3*sig^2)
form <- gelModel(gform, NULL, gelType="EEL", theta0=theta0, vcov="MDS", data=dat)
form
@ 

\item function:   
  
<<>>=  
fct <- function(theta, x)
    cbind(x-theta[1], (x-theta[1])^2-theta[2],
          (x-theta[1])^3, (x-theta[1])^4-3*theta[2]^2)
dfct <- function(theta, x)
    {
        m1 <- mean(x-theta[1])
        m2 <- mean((x-theta[1])^2)
        m3 <- mean((x-theta[1])^3)
        matrix(c(-1, -2*m1, -3*m2, -4*m3, 
                 0, -1, 0, -6*theta[2]), 4, 2)
    }
theta0=c(mu=1,sig2=1)
func <- gelModel(fct, simData$x3, theta0=theta0, grad=dfct, vcov="iid", gelType="ET")
func
@ 

\item Non-linear models:

<<>>= 
theta0=c(b0=1, b1=1, b2=1)
gform <- y~exp(b0+b1*x1+b2*x2)
nlin <- gelModel(gform, ~z1+z2+z3+x2, theta0=theta0, vcov="MDS", data=simData,
                 gelType="HD")
nlin
@
\end{itemize}

It is also posssible to convert an existing gmmModels to gelModels:

<<>>=
nlin <- gmmModel(gform, ~z1+z2+z3+x2, theta0=theta0, vcov="MDS", data=simData)
nlin <- gmmToGel(nlin, gelType="HD")
@ 

\subsection{The rhoXXX functions}

The package provides $\rho(v)$ for ET, EL, EEL and HD. The function
names are respectively ``rhoET'', ``rhoEL'', ``rhoEEL'' and ``rhoHD''.
For any other GEL, users can pass user specific $\rho(v)$ function to
the rhoFct argument of the gelModel(). The following example shows how
the function must be built:

<<>>=
rhoEL
@ 

Therefore, the function must be in the form $f(X,\lambda,d,k)$, where
the first argument is an $n\times q$ matrix, the second argument is a
vector of $q$ elements, the third is an integer that indicates the
order of derivative to return, and the last is a scalar that depends
on the kernel used to smooth the moment function. We will discuss that
in more details below. The function must return the vector $\rho(k
X\lambda)$, $\rho'(k X\lambda)$ or $\rho''(k X\lambda)$, when derive
is 0, 1, or 2, where $\rho'(v)$ and $\rho''(v)$ are the first and
second derivative of $\rho(v)$.

\subsection{The Lagrange multiplier solver}

The function getLambda() function solve the maximization problem 
\[
\max_\lambda \frac{1}{n} \sum_{i=1}^n \rho(\lambda'X_i)
\]
It is used to solve problem (\ref{gel_obj}). The arguments are:

<<>>=
args(getLambda)
@ 

The first argument is the $n\times q$ matrix $X$. The second argument
is the starting value for $\lambda$. If set to NULL, a vector of
zeroes is used. The third argument is the GEL type, which is either
"ET", "EL", "EEL", "REEL" or "HD". If the rhoFct is provided, getType
is ignored. The argument control is used to pass a list of arguments
to optim(), nlminb() or constrOptim(). The argument ``k'' is the
scalar described in the previous subsection. To describe all other
arguments, we are presenting the options by type of GEL:

\begin{itemize}
\item EL: There are three possible options for EL. The default is
  ``nlminb'', in which case, the arguments tol, maxiter and method are
  ignored. If algo is set to ``optim'', the solution is obtained using
  constrOptim(), with the restriction $(1-\lambda'X_i)>0$ for all
  $i$. If algo is set to ``Wu'', the \cite{wu05} algorithm is
  used. The argument tol and maxit are used to control the stopping
  rule. 

\item HD: Identical to EL, except that the ``Wu'' algorithm is not
  available for that type of GEL.

\item EEL: There is an analytical solution, so all other arguments are
  ignored.

\item REEL: This is EEL with a non-negativity constraint on all
  implied probabilities. In that case, the maxiter can be used to
  control the number of iterations.

\item Others: When rhoFct is provided or the type is ET, the solution
  is obtained by either ``nlminb'' or ``optim''. In that case, the
  algorithms are controlled through the control argument.
\end{itemize}

Here are a few example using the simulated dataset (convergence code
of 0 means that the algorithm converged with no detected problem):

<<>>=
X <- simData[c("x3","x4","z5")]
(res <- getLambda(X, gelType="EL"))$lambda
res$convergence$convergence
@ 

<<>>=
(res <- getLambda(X, gelType="EL", algo="Wu"))$lambda
res$convergence$convergence
@ 

<<>>=
(res <- getLambda(X, gelType="ET",control=list(maxit=2000)))$lambda
res$convergence$convergence
@ 

The following shows that we can provide getLambda() with a rhoFct instead:

<<>>=
(res <- getLambda(X, rhoFct=rhoEEL))$lambda
res$convergence$convergence
@ 

Although we rarely call the function directly, it is good to
understand how it works, because it is an important part of the
estimation procedure.

\section{Methods for gelModels Classes} \label{sec:gelmodels-methods}

We saw above that any ``gelModels'' is a class that contains one of
the ``gmmModels'' class object.  Therefore, many ``gmmModels'' methods
can be applied to ``gelModels'' through this direct inheritance. when
it is the case, we will specify ``gmmModels inherited method''. 


\begin{itemize}
\item \textit{kernapply}: In the case of weakly dependent moment
  conditions, we saw above that the moment function must be smoothed
  using the following expression:
\[
g^w_t(\theta) = \sum_{s=-m}^m w(s)g_{t-s}(\theta)
\]

When a GEL model is defined with vcov="HAC", the specification of the
kernel is stored in the ``wSpec'' slot of the object. For example, we
can define the linear model above with the HAC specification:

<<>>=
linHAC <- gelModel(y~x1+x2, ~x2+z1+z2, data=simData, vcov="HAC", gelType="EL")  
linHAC
@ 

The optimal bandwidth is computed when the model is created, and
remains the same during the estimation process, unless another one is
specified. The above model shows that the default kernel is the
``Truncated'' one, and the default bandwidth is based on
\cite{andrews91}. The bandwidth is not based on the smoothing kernel,
but on the implied kernel for the HAC estimation. \cite{smith01} shows
that when $g_t(\theta)$ is replaced by $g^w_t(\theta)$,
$V=\sum_{i=1}^n g^w_t(\theta)g^w_t(\theta)'/n$ is an HAC estimator of
the covariance matrix of $\sqrt{n}\bar{g}(\theta)$, with Bartlett
kernel when the smoothing kernel is the Truncated, and with Parzen
kernel when the smoothing kernel is the Bartlett. The optimal bandwidth
above is therefore based on the Bartlett kernel. 

It is possible to modify the specifications of the kernel and
bandwidth through the argument vcovOptions (See help(vcovHAC) from the
sandwich package for all possible options). Notice that the kernel
type that is passed is the kernel used for the HAC estimation, not the
smoothing of $g_t(\theta)$. See in the following example that the
Parzen kernel is selected, which implies a Bartlett kernel for the
smoothing of $g_t(\theta)$.

<<>>=
linHAC2 <- gelModel(y~x1+x2, ~x2+z1+z2, data=simData, vcov="HAC", 
                    gelType="EL", 
                    vcovOptions=list(kernel="Parzen", bw="NeweyWest", prewhite=1))  
linHAC2
@ 

It is also possible to set the bandwidth to a fix number:

<<>>=
linHAC3 <- gelModel(y~x1+x2, ~x2+z1+z2, data=simData, vcov="HAC", 
                    gelType="EL", 
                    vcovOptions=list(kernel="Parzen", bw=3, prewhite=1))  
linHAC3
@ 

The \textit{kernapply} method, which is defined as an S3 method in the
stats package, uses the information contained in the ``wSpec'' slot to
compute the $n\times q$ matrix of moment with the i$^{th}$ row being
$g_t^w(\theta)'$. A theta is required, because we need to evaluate
$g_t(\theta)$.

<<>>=
gw <- kernapply(linHAC, theta=c(1,1,1))$smoothx
head(gw)
@ 

The function also returns the weights, bandwidth, kernel name and the
scalars $k_1$ and $k_2$ that are needed for the asymptotic properties
of the estimators (see \cite{anatolyev05}). If the argument
smooth is set to FALSE, the optimal bandwidth is computed and no
smoothing is done. By default, the first step GMM estimator with the
identity matrix is used, unless theta is provided.

<<>>=
kernapply(linHAC, smooth=FALSE)
@ 

There is also a \textit{kernapply} method for ``gmmModels''
classes. For now, it only returns the optimal bandwidth, the weights, 
the kernel names and the $k_i$'s.

<<>>=
kernapply(as(linHAC, "gmmModels"))
@ 

\item \textit{residuals (gmmModels inherited method)}: Only defined
  for linearGel and nonlinearGel. It returns $\epsilon(\theta)$:

\item \textit{Dresiduals (gmmModels inherited method)}: Only for
  ``linearGel'' and ``nonlinearGel'', it returns the $n\times k$
  matrix $d\epsilon(\theta)/d\theta$:

\item \textit{model.matrix (gmmModels inherited method)}: For
  linearGel and nonlinearGel only. For both classes, it ca be used to
  get the matrix of instruments:

\item \textit{modelResponse (gmmModels inherited method)}: For linear
  model only, it returns the vector of response. It is not defined for
  nonlinearGel classes because the left hand side is not always
  defined.

\item \textit{"[" (gmmModels inherited method)}: It creates a new
  object of the same class with a subset of moment conditions:

\item \textit{as}: ``linearGel'' can be converted into a
  ``nonlinearGel'' or ``functionGmm''. Also, ``nonlinearGel'' and
  ``formulaGel'' can be converted to ``functionGel''

<<>>=
as(lin, "nonlinearGel")
as(nlin, "functionGel")
@   

\item \textit{subset (gmmModels inherited method)}: As for the S3
  method, it creates the same class of object with a subset of the
  sample.

\item \textit{evalMoment}: It computes the $n\times q$ matrix of
  moments, with the $i^{th}$ row being $g_i(\theta)'$, when the
  ``vcov'' slot is not "HAC", and $g_i^w(\theta)'$ when it is.

<<>>=
gt <- evalMoment(linHAC, theta=1:3)
@   
  
\item \textit{evalDMoment}: It computes the $p\times k$ matrix of
  derivatives of the sample mean of $g_i(\theta)$. It calls the next
  method when the slot ``vcov'' is not "HAC". Otherwise, a numerical
  derivative is computed using numericDeric().

\item \textit{momentVcov}: It calls the next method when the slot
  ``vcov'' is not "HAC". Otherwise, it returns 
  
\[
V = \frac{1}{n}\sum_{i=1}^n g_t^w(\theta)g_t^w(\theta)'
\]

\item \textit{update}: This method is used to modify existing
  objects. For now, only the covariance structure, the gelType and
  rhoFct can be modified. 
  
<<>>=
update(lin, vcov="HAC", gelType="ET")
@   

\end{itemize}

\section{Restricted models} \label{sec:gelmodels-rest}

As for ``gmmModels'', restrictions can be imposed on the
coefficients. The union class for all restricted GEL models is
``rgelModels''. The classes are ``rlinearGel'', ``rformulaGel'',
``rfunctionGel'' and ``rnonlinearGel''. Each one contains its
unrestricted model plus additional slots that specify the
constraints. See the gmmS4 vignette for more details. The constructor
is the \textit{restModel} method.

<<>>=
lin2 <- gelModel(y~x1+x2+x3+z1, ~x1+x2+z1+z2+z3+z4, data=simData,
                 gelType="EL", vcov="MDS")
rlin2 <- restModel(lin2, c("x1=x2", "x3=0"))
rlin2
@ 

All methods described in the previous section also apply to the
restricted models. For example, 

<<>>=
e <- residuals(rlin2, theta=c(1,1,1)) ## we now have 3 coefficients
gt <- evalMoment(rlin2, theta=c(1,1,1))
@ 

To recover the full coefficient vector, we use the \textit{coef}
method:

<<>>=
coef(rlin2, theta=1:3)
@ 

\section{The \textit{solveGel} Method} \label{sec:gelmodels-solve}

The main method to estimate a model by GEL methods is
\textit{solveGel}. The available signatures are:

<<>>=
showMethods("solveGel")
@ 

The arguments are 
\begin{itemize}
\item theta0: The initial value for the minimization algorithm. It is
  required if the model does not have a theta0 slot. If it has a
  theta0 slot, it is used by default unless a new theta0 is provided.
\item lambda0: The initial value to pass to the lambda solver. By
  default, it is set to 0, which is its asymptotic value in case of
  correctly specified models.
\item lamSlv: An optional function to solve for lambda. By default,
  getLambda() is used. The function must have the following form:

<<>>=
mylSolve <- function(gmat, lambda0, gelType=NULL, rhoFct=NULL, k=1, ...) 
    {
        lambda <-  rep(0,ncol(gmat))
        obj <-  sum(colMeans(gmat)^2)
        list(lambda=lambda, convergence=0, obj=obj)
    }
@ 

Therefore, it must return a list with lambda, convergence and obj. In
the above example, $\lambda$ is set to a vector of zeros and the
returned obj is $\bar{g}(\theta)'\bar{g}(\theta)$. The solution will
therefore be the one step GMM with the weighting matrix equals to the
identity.

<<>>=
solveGel(lin,c(0,0,0), lamSlv=mylSolve)
@ 

To present a more realistic example, suppose we want to estimate the
model using the exponentially tilted empirical likelihood (ETEL)
method of \cite{schennach07}, we could write a function that solves
the lambda using ET, and returns the empirical log-likelihood ratio:

<<>>=
mylSolve <- function(gmat, lambda0=NULL, gelType=NULL, rhoFct=NULL, k=1, ...) 
    {
        gmat <- as.matrix(gmat)
        res  <-  getLambda(gmat, lambda0, gelType="ET", k=k)
        gml <- c(gmat%*%res$lambda)
        w <- exp(gml)
        w <- w/sum(w)
        n <- nrow(gmat)
        res$obj <- mean(-log(w*n))
        res
    }
etelFit <- solveGel(lin,c(1,1,0), lamSlv=mylSolve)
etelFit$theta
@

That's equivalent to setting gelType to ``ETEL'':

<<>>=
solveGel(update(lin, gelType="ETEL"), c(1,1,0))$theta
@ 

\item coefSlv: A character string that indicates the name of the
  minimization solver used to obtain $\hat{\theta}$. By default,
  "optim" is use. The other options are "nlminb" and "constrOptim". 
  
\item lControl: A list of options for the lambda solver. It is passed
  to getLambda() or lamSlv() if provided. For example, we can use the
  Wu method for EL as follows:

<<>>=
solveGel(lin, c(1,1,0), lControl=list(algo="Wu"))$theta
@   

\item tControl: A list of control for the coefSlv function. We could,
  for example, use the following options:

<<>>=
solveGel(lin, c(1,1,0), lControl=list(algo="Wu"),
         tControl=list(method="BFGS", control=list(maxit=2000, reltol=1e-9)))$theta
@   

In that particular case, the list is directly passed to optim().
   
\end{itemize}

The method returns a list with: theta=$\hat{\theta}$,
lambda=$\hat{\lambda}$, convergence = convergence message and code for
$\theta$, and lconvergence = convergence message and code for
$\lambda$.

\section{The \textit{modelFit} Method} \label{sec:gelmodels-modelfit}

This is the main estimation method. It returns an object of class
``gelfit''. The arguments are:

\begin{itemize}
\item object: Any object that belongs to the union class ``gelModels''
\item getType: Optional type of GEL if we want to estimate the model
  with a type that is different from the one defined in the object.  
\item rhoFct: Optional $\rho(v)$ function if we want to estimate the
  model with a function that is different from the one defined in the
  object.
\item initTheta: Method to obtain the starting value for $\theta$. By
  default, the one step GMM is used. The other option is to use the
  one included in the object.
\item theta0: The stating value for $\theta$. If provided, the
  argument initTheta is ignored.
\item lambda0: Starting value for $\lambda$. By default, a vector of
  zeros is used.
\item vcov: Logical argument that specifes if the covariance matrices
  of $\hat{\theta}$ and $\hat{\lambda}$ should be computed? It is
  FALSE by default.
\item ... : Additional argument that is passed to the
  \textit{gelSolve} method.  
  \end{itemize}

In general, it works fine with the default arguments:

<<warning=FALSE>>=
fit <- modelFit(lin)
@ 

The following slots are available for the ``gelfit'' object:

<<>>=
showClass("gelfit")
@ 

\subsection{Methods for ``gelfit'' classes} \label{sec:gelmodels-gelfitm}

\begin{itemize}
  
\item \textit{print}: It prints the model, $\hat{\theta}$ and
  $\hat{\lambda}$. The arguments ``model'' and ``lambda'' can be set
  to FALSE to avoid printing them.
  
<<>>=
fit <- modelFit(lin, lControl=list(algo="Wu"))
print(fit, lambda=FALSE, model=FALSE)
@   

\item \textit{residuals}: For ``linearGel'' and ``nonlinearGel'', it
  returns the difference between the left hand side and right hand
  side.
  
\item \textit{getImpProb}: It computes the vector of implied
  probabilities $\hat{p}_i$'s. By default, they are defined as:
  \[
  \hat{p}_i = \frac{-\rho'(g_i(\hat{\theta}))/n}{\sum_{j=1}^n -\rho'(g_j(\hat{\theta}))/n}
  \]
  The options are
  \begin{itemize}
    \item posProb: This option is only considered for EEL type of
      GEL. If set to TRUE, the method of
      \citet{antoine-bonnal-renault07} is used to compute the 
      probabilities:
\[      
\tilde{p}_i = \frac{\hat{p}_i + \varepsilon/n}{1+\varepsilon},
\]
where $\varepsilon=-n\min(\min_i(\hat{p}_i), 0)$, and
$\hat{p}_i=-\rho'(g_i(\hat{\theta}))/n$, which is the unormalized
version of the above definition. It is then normalized to sum to
1. The method is only needed when we want to compute moments based on
them. It is therefore set to FALSE by default.
\item normalize: If TRUE, the default, the above normalized version is
  returned. If FALSE, it returns $-\rho'(g_i(\hat{\theta}))/n$. 
    \end{itemize}

The method returns a list with pt, the vector $\{\hat{p}_i\}$,
convMom = $\sum_{i=1}^n \hat{p}_ig_i(\hat{\theta})$, and
convProb = $|(\sum_{i=1}^n \hat{p}_i)-1|$. convMom is important,
because it indicates if the estimation went well. It should be a
vector close to zero.

<<>>=
pt <- getImpProb(fit)
pt$convMom
@ 
  
\item \textit{vcov}: It returns the covariance matrices of
  $\hat{\theta}$ and $\hat{\lambda}$ in a list. The returned
  covariance matrix for $\hat{\theta}$ is:

\[
\hat{\Sigma} = \frac{1}{n}\left[\hat{G}'\hat{\Omega}^{-1} \hat{G} \right]^{-1}
\]
  
when the ``vcov'' component of the object is not ``HAC'', with

\[
\hat{G} = \frac{1}{n}\sum_{i=1}^n \frac{dg_i(\hat{\theta})}{d\theta},
\]

and

\[
\hat{\Omega} = \frac{1}{n}\sum_{i=1}^n g_i(\hat{\theta})
  g_i(\hat{\theta})'.
\]

For HAC specification, the covariance matrix is:

\[
\hat{\Sigma}_w = \frac{1}{n}\left[\hat{G}_w'\hat{\Omega}_w^{-1} \hat{G}_w\right]^{-1},
\]

with

\[
\hat{G}_w = \frac{1}{nk_1}\sum_{i=1}^n \frac{dg^w_i(\hat{\theta})}{d\theta}
\]

and

\[
\hat{\Omega}_w = \frac{b}{nk_2}\sum_{i=1}^n g^w_i(\hat{\theta})
  g_i^w(\hat{\theta})',
\]

where $b$ is the bandwidth and the scalars $k_1$ and $k_2$ are
determined by the kernel. The values of $\{k_1,k_2\}$ are $\{2,2\}$
when the smoothing is based on the Truncated kernel, which implies
Bartlett for the HAC estimator, and $\{1,2/3\}$ when the smoothing is
based on the Bartlett kernel, which implies Parzen for the HAC
estimator.

Using the above definitions, the returned covariance matrix for
$\hat{\lambda}$ is

\[
\widehat{Var(\hat{\lambda})} = \frac{1}{n}\left[\hat{\Omega}^{-1}  -
\hat{\Omega}^{-1} \hat{G} \hat{\Sigma} \hat{G}'\hat{\Omega}^{-1} \right]
\]

for non-smoothed moments, and 

\[
\widehat{Var(\hat{\lambda})}_w = \frac{b^2}{n}\left[\hat{\Omega}_w^{-1}  -
\hat{\Omega}_w^{-1} \hat{G}_w \hat{\Sigma}_w \hat{G}_w'\hat{\Omega}_w^{-1} \right]
\]

for smoothed moments. The method has two additional arguments. The
first is ``withImpProb'', which is FALSE by default. if set to TRUE,
all moment estimations in the form $\sum_{i=1}^n[]_i/n$ are replaced
by $\sum_{i=1}^n \hat{p}_i[]_i$. The second argument is tol, which is
a tolerance level for too small diagonal elements of the covariance
matrix of $\hat{\lambda}$. When some moment conditions are not
binding, the estimated variance of the associated Lagrange multiplier
may be too small or even negative, which is a numerical problem. To
avoid negative values, tol is the minimum value the diagonal elements
can take.

\item \textit{summary}: It returns an object of class
  ``summaryGel''. It returns the usual tables in estimation
  methods. The only argument is ... which is passed to the
  \textit(vcov) method.
  
<<>>=
summary(fit)
@   

\item{specTest} It returns the likelihood ratio (LR), Lagrange
  multiplier (LM) and J test, for the hypothesis
  $H_0:\E(g(\theta))=0$. The signature is ("gelfit", "missing"), so
  the second argument, which, is not used. The argument type is set to
  "ALL" by default, which means that the three test are
  returned. Alternatively we can specify a single test. It returns an
  object of class ``specTest'' which possesses a \textit{print}
  method.
  
<<>>=
specTest(fit)
@   

\item \textit{confint}: It returnd confidence itervals for $\theta$ or
  $\lambda$ By default, a simple Wald type interval is
  constructed. The parm argument allows to select just a few
  parameters. By default, it is done for all.
  
<<>>=
confint(fit, parm=1:2, level=0.90)
confint(fit, level=0.90, lambda=TRUE)
@ 

The ``vcov'' argument is used to provide the method with another
covariance matrix. The ... is passed to the \textit{vcov} method.

Confidence interval can also be semi-parametric, by inverting any of
the specification test. To undertand how it is constructed, let
us define $\theta_{-i}$ as the vector $\theta$ without $\theta_i$, and
$\tilde{\theta}_{-i}(\theta_i)$ its estimate for a given
$\theta_i$. Let $S(\theta_i, \theta_{-i})$ be one of the specification
test evaluated at $\{\theta_i, \theta_{-i}\}$. Under the null that
$\theta_i$ is the true value, 

\[
T(\theta_i) = S(\theta_i, \tilde{\theta}_{-i}(\theta_i))-S(\hat{\theta_i},\hat{\theta}_{-i})
\conD \chi^2_1
\]

The following $(1-\alpha)$ confidence interval for $\theta_i$ is therefore 
asymptotically valid (given some regularity conditions):

\[
\{\theta_i | T(\theta_i) \leq C_{1-\alpha}\}
\]

where $C_{1-\alpha}$ is the $(1-\alpha)$ quantile of the $\chi^2_1$
distribution. To get $\tilde{\theta}_{-i}$, we need to estimate a
restricted model for each $\theta_i$ and search for
$T(\theta_i)=C_{1-\alpha}$. This is done by setting type "invLR",
"invLM", or "invJ". A function that returns $[T(\theta_i)-C_{i-\alpha}]$
is passed to the uniroot() function using intervals on both sides of
$\hat{\theta}_i$. The argument ``fact'' is used to control the
wideness of the interval passed to uniroot(). By default, the two
intervals are (one for the left value and one for the right value of
the confidence interval) $[\hat{\theta}_i-3s_i, \hat{\theta}_i]$ and
$[\hat{\theta}_i, \hat{\theta}_i+3s_i]$, where $s_i$ is the standard
error of $\hat{\theta}_i$. If the method fails, it is possible to
adjust the intervals with ``fact''.

<<>>=
confint(fit, 1:2, type="invLR", level=0.90)
@ 

A common application in introductory course on EL, is to compute EL
confidence interval for a mean. Here, it is done by first creating a
model with only one intercept and an intercept as instrument:

<<>>=
muModel <- gelModel(x1~1, ~1, gelType="EL", data=simData)
@ 

We then fit the model:

<<>>=
muFit <- modelFit(muModel, tControl=list(method="Brent", lower=-10, upper=10),
                  lControl=list(algo="Wu"))
muFit@theta
@ 

The solution is just the sample mean:

<<>>=
mean(simData$x1)
@ 

We can then compute the EL confidence interval:

<<>>=
confint(muFit, type="invLR")
@ 

We will see below that we can construct GEL intervals in one step,
using the \textit{confint} method for ``numeric'' vectors.

\item \textit{update}: The method is used to re-estimate a model with
  different specifications, keeping all the others equal. Suppose we
  start with the estimation using the \cite{wu05} algorithm:
  
<<>>=
fit <- modelFit(lin, lControl=list(algo="Wu"))
fit@theta
@   

We want to re-estimate the model with the same algorithm for $\lambda$
but a different one for $\theta$:

<<>>=
fit2 <- update(fit, coefSlv="nlminb")
fit2@theta
@ 

We can also change the type of GEL (here we reset the lControl because
"Wu" is only for EL):

<<>>=
fit3 <- update(fit2, gelType="ET", lControl=list())
fit3@theta
@ 

It is also possible to pass a new model to \textit{update}. This is
particularly useful to estimate a restricted model with the same
numerical methods. This is used by \textit{confint} to compute the
interval by the inverse of the specification test. 

<<>>=
rlin <- restModel(fit3@model, "x1=1")
update(fit3, newModel=rlin)
@ 

Here, fit3 is an ET estimation. If we restrict the model lin, which is
EL, the \textit{update} will also use EL. That's why
\textit{restModel} is applied to the model in fit3.
\end{itemize}

\section{The \textit{evalModel} Method} \label{sec:gelmodels-evalmodel}

This method create a ``gelfit'' object without estimation. It is
possible to simply fix $\lambda$ and $\theta$:

<<>>=
print(evalModel(lin, theta=c(1,2,3), lambda=rep(.1,4)), model=FALSE)
@ 

If the $\lambda$ is not provided, then it is estimated for the given
$\theta$. It is like calling getLambda() with $g(\theta)$ as
"gmat". The difference is that a ``gelfit'' object is returned. It is
particularly usefull when we estimate restricted models in which the
number of restriction is equal to the number of coefficients. It is
use by \textit{confint} method for the confidence interval on the mean
(see above):

<<>>=
specTest(evalModel(muModel, theta=4), type="LR")
@ 

The problem with the \textit{evalModel} is that not much effort is
put on adjusting the parameters of the model. Above, it says that the
degrees of freedom is 0. It is just not an estimation method. A proper
estimation of the above would be done with \textit{modelFit}:

<<>>=
rmuModel <- restModel(muModel, R=matrix(1,1,1), rhs=4)
specTest(modelFit(rmuModel))
@ 

In that case \textit{modelFit} is calling \textit{evalModel}. 

\section{One function to fit them all: gel4} \label{sec:gelmodels-gel4}

Most users will prefer to avoid going through the steps of building a
model and fitting it. The gel4() function build the model, fit it and
return the ``gelfit'' object. The arguments are similar to the ones
described above for \textit{modelFit}, \textit{gelSolve} and
gelModel(). 

\begin{itemize}  
  \item Arguments for the model: ``g'', ``x'', ``theta0'',
    ``gelType'',''rhoFct'', ``vcov'', ``grad'', ``vcovOptions'',
    ``centeredVcov'', and ``data''. See gelModel() above for
    details. The additional arguments ``cstLHS'' and ``cstRHS'' are to
    estimate restricted models. ``chstLHS'' is passed to
    \textit{restModel} as ``R'' and ``cstRHS'' is passed as
    ``rhs''. The default getType is "EL", and the default ``vcov'' is
    "MDS"
  \item Arguments for the estimation: ``lamSlv'', ``coefSlv'',
    ``initTheta'', ``lControl'' and ``tControl''. The default coefSlv
    is "optim", the default lamSlv is getLambda(), and the default
    initTheta is "gmm". See \textit{solveGel} and \textit{modelFit}
    above for more details.
  \item The argument ``getVcov'' is passed to \textit{modelFit} as
    vcov. Therefore, if it is set to TRUE, the covariance matrices are
    computed.
\end{itemize}

We can estimate the models from Section \ref{sec:gelmodels} as follows.

<<>>=
fit <- gel4(y~x1+x2, ~x2+z1+z2, data=simData, vcov="iid", gelType="EL",
             lControl=list(algo="Wu"))  
print(fit, model=FALSE)
@ 

To change the initial values in the linear case, we have to provide it
and set initTheta to "theta0". 

<<>>=
fit <- gel4(y~x1+x2, ~x2+z1+z2, data=simData, vcov="iid", gelType="EL",
             lControl=list(algo="Wu"), theta0=c(1,1,0), initTheta="theta0")  
coef(fit)
@ 

To estimate the model with the restiction $x1=x2$, we set $cstLHS$ as
$R$ in the \textit{restModel} method:

<<>>=
fit <- gel4(y~x1+x2, ~x2+z1+z2, data=simData, vcov="iid", gelType="EL",
             lControl=list(algo="Wu"), cstLHS="x2=x1")
print(fit, model=FALSE)
@ 


For the formula type, a named theta0 is required for the same reason
it is required in gelModel(). The names are used to locate the
coefficients in the formulas.


<<>>=
theta0=c(mu=1,sig=1)
x <- simData$x1
dat <- data.frame(x=x, x2=x^2, x3=x^3, x4=x^4)
gform <- list(x~mu,
              x2~mu^2+sig, 
              x3~mu^3+3*mu*sig,
              x4~mu^4+6*mu^2*sig+3*sig^2)
fit <- gel4(g=gform, gelType="EEL", theta0=theta0, vcov="MDS", data=dat)
print(fit, model=FALSE)
@ 

For the function type, theta0 is required because the moment function
is evaluated when the model is created. It is also the starting value
if initTheta is set to "theta0". the argument x must be provided,
because it is the second argument of the moment function

<<>>=  
fct <- function(theta, x) 
   cbind(x-theta[1], (x-theta[1])^2-theta[2],
          (x-theta[1])^3, (x-theta[1])^4-3*theta[2]^2)
dfct <- function(theta, x)
    {
        m1 <- mean(x-theta[1])
        m2 <- mean((x-theta[1])^2)
        m3 <- mean((x-theta[1])^3)
        matrix(c(-1, -2*m1, -3*m2, -4*m3, 
                 0, -1, 0, -6*theta[2]), 4, 2)
    }
fit <- gel4(g=fct, x=simData$x3, theta0=c(1,1), grad=dfct, vcov="iid", gelType="ET")
print(fit, model=FALSE)
@ 

The last type is non-linear models, which requires a named theta0 as
for the formula type. 
  
<<>>= 
theta0=c(b0=1, b1=0, b2=0)
gform <- y~exp(b0+b1*x1+b2*x2)
fit <- gel4(gform, ~z1+z2+z3+x2, theta0=theta0, vcov="MDS", data=simData,
                 gelType="HD")
print(fit, model=FALSE)
@

\section{GEL confidence intervals for the mean}

The method \textit{confint} can also be used to construct confidence
intervals for the mean, or confidence region for two means. The first
method is for ``numeric'' objects:

<<>>=
x2 <- simData$x2
confint(x2, gelType="EL")
confint(x2, gelType="EL", type="invLR")
@

Which can also be done using the method for ``data.frame'':

<<eval=FALSE>>=
confint(simData, "x2", gelType="EL")
@ 

The arguments ``level'', ``fact'' and ``type'' are as for the method
with ``gelfit'' signature. The ``parm'' is only used with
``data.frame'' in which case, it is used to select one or two
columns. The argument ``vcov'' is used to specify the type of data is
stored in the object. The options are ``iid'', the default, or ``HAC''
for weakly dependent processes.  

For ``data.frame'' and two variables, an object of class ``mconfint''
is created. The argument ``npoints'' is the number of points to use to
construct the region. The arguments ``cores'' is for the number of
cores to use with mclapply(). For Windows operating systems, it is set
to 1. The following shows how to use the \textit{print} and
\textit{plot} methods for that class. Here is an example which
compares Wald and LR confidence regions. 

<<>>=
res <- confint(simData, c("x2","y"), npoints=20)
res
@ 

The following is not run because it creates some misterious error when
the package is checked. Beside that, it works perfectly. Try it.

\begin{center}
\begin{minipage}{.7\textwidth}
<<fig.height=5, eval=FALSE>>=
res2 <- confint(simData, c("x2","y"), type="invLR", npoints=20)
c1 <- col2rgb("darkorange2")/255
c1 <- rgb(c1[1],c1[2],c1[3],.5)
c2 <- col2rgb("lightblue2")/255
c2 <- rgb(c2[1],c2[2],c2[3],.5)
plot(res, pch=20, bg=1, Pcol=c1, col=c1, density=10, ylim=c(3.5,6.5),
     xlim=c(4.8,7.5))
plot(res2, pch=20, bg=2, Pcol=c2, col=c2, density=10, add=TRUE)
legend("topright", c("Wald","LR"), col=c(c1,c2), pch=20 , bty="n")
@ 
\end{minipage}
\end{center}

The arguments ``main'', ``xlab'' ``ylab'', ``pch'', ``ylim'',
``xlim'', ``Pcol'' (the color of the points) and ``bg'' are passed to
plot.default(), and all other arguments are passed to polygon().

\bibliography{empir}

\appendix
\section{Some extra codes}
The following \textit{extract} is used with the ``texreg'' package of
\cite{leifeld13} to produce nice latex tables.

<<extract, message=FALSE, warning=FALSE>>=
library(texreg)
setMethod("extract", "gelfit", 
          function(model, includeSpecTest=TRUE, 
                   specTest=c("LR","LM","J"), include.nobs=TRUE, 
                   include.obj.fcn=TRUE, ...)
              {
                  specTest <- match.arg(specTest)
                  s <- summary(model, ...)
                  wspecTest <- grep(specTest, rownames(s@specTest@test))
                  spec <- modelDims(model@model)
                  coefs <- s@coef
                  names <- rownames(coefs)
                  coef <- coefs[, 1]
                  se <- coefs[, 2]
                  pval <- coefs[, 4]
                  n <- model@model@n
                  gof <- numeric()
                  gof.names <- character()
                  gof.decimal <- logical()
                  if (includeSpecTest) {
                      if (spec$k == spec$q)
                          {
                              obj.fcn <- NA
                              obj.pv <- NA
                          } else {
                              obj.fcn <- s@specTest@test[wspecTest,1]
                              obj.pv <- s@specTest@test[wspecTest,3]
                          }
                      gof <- c(gof, obj.fcn, obj.pv)                      
                      gof.names <- c(gof.names, 
                                     paste(specTest,"-test Statistics", sep=""),
                                     paste(specTest,"-test p-value", sep=""))
                      gof.decimal <- c(gof.decimal, TRUE, TRUE)
                  }
                  if (include.nobs == TRUE) {
                      gof <- c(gof, n)
                      gof.names <- c(gof.names, "Num.\\ obs.")
                      gof.decimal <- c(gof.decimal, FALSE)
                  }
                  tr <- createTexreg(coef.names = names, coef = coef, se = se, 
                                     pvalues = pval, gof.names = gof.names, gof = gof, 
                                     gof.decimal = gof.decimal)
                  return(tr)
              })
@ 

Here is an example

<<results='asis'>>=
fit1 <- gel4(y~x1, ~x2+x3+x4, data=simData)
fit2 <- gel4(y~x1+x2, ~x2+x3+x4, data=simData)
texreg(list(fit1,fit2), digits=4)
@ 

\end{document} 

